import streamlit as st

from .config import DATA_DIR
from .vectorstore import (
    sync_pdf_dir,
    save_uploaded_pdf_to_dir,
    list_ingested_pdfs,
)


def render_chat(conversational_chain):
    # ====== (ì„ íƒ) ìƒë‹¨ ìƒíƒœ ======
    st.caption(f"ğŸ“ ë°ì´í„° í´ë”: {DATA_DIR}  (ì´ í´ë”ì˜ PDF ì „ì²´ë¥¼ ëŒ€ìƒìœ¼ë¡œ ì‹ ê·œë§Œ ì„ë² ë”©í•©ë‹ˆë‹¤)")

    # ====== ì±„íŒ… ì„¸ì…˜ ìƒíƒœ ======
    if "messages" not in st.session_state:
        st.session_state["messages"] = [
            {"role": "assistant", "content": "ğŸ“ PDFë¥¼ ì²¨ë¶€í•˜ë ¤ë©´ ì•„ë˜ì— ë“œë˜ê·¸ì•¤ë“œë¡­ í•´ì£¼ì„¸ìš”. ê·¸ë¦¬ê³  ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš” ğŸ™‚"}
        ]

    # ====== ê¸°ì¡´ ì±„íŒ… ë©”ì‹œì§€ ë Œë”ë§ ======
    for msg in st.session_state["messages"]:
        st.chat_message(msg["role"]).write(msg["content"])

    # ====== (2ë²ˆ ë°©ì‹) ì—…ë¡œë”ë¥¼ ì±„íŒ… íë¦„ ì•ˆì— ì‚½ì… ======
    with st.chat_message("assistant"):
        st.write("ì—¬ê¸°ì— PDFë¥¼ ë“œë˜ê·¸ì•¤ë“œë¡­ í•˜ì‹œë©´ `./data`ì— ì €ì¥ë˜ê³ , **ìƒˆë¡œ ì¶”ê°€ëœ PDFë§Œ** ì„ë² ë”©ë©ë‹ˆë‹¤. ğŸ“š")

        uploaded_files = st.file_uploader(
            "PDF ì—…ë¡œë“œ",
            type=["pdf"],
            accept_multiple_files=True,
            label_visibility="collapsed",
        )

    # ì—…ë¡œë“œ ì²˜ë¦¬ (ì—…ë¡œë“œë˜ë©´ ë°”ë¡œ ì €ì¥ + ë™ê¸°í™”)
    if uploaded_files:
        # ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ íŒŒì¼ë“¤ì„ 'ì±„íŒ… ë©”ì‹œì§€'ì²˜ëŸ¼ í‘œì‹œ
        for uf in uploaded_files:
            st.chat_message("human").write(f"ğŸ“ ì—…ë¡œë“œë¨: {uf.name}")

        # ì‹¤ì œ ì €ì¥/ì„ë² ë”©
        with st.spinner("ì—…ë¡œë“œ íŒŒì¼ ì €ì¥ ë° ì‹ ê·œ PDF ì„ë² ë”© ì¤‘..."):
            # 1) ./dataì— ì €ì¥
            for uf in uploaded_files:
                save_uploaded_pdf_to_dir(uf, DATA_DIR)

            # 2) ./data ì „ì²´ ìŠ¤ìº” â†’ ì‹ ê·œ PDFë§Œ ì„ë² ë”©
            result = sync_pdf_dir(DATA_DIR)

        # ê²°ê³¼ë¥¼ assistant ë©”ì‹œì§€ì²˜ëŸ¼ í‘œì‹œ
        summary_lines = [
            f"âœ… ë™ê¸°í™” ì™„ë£Œ!",
            f"- ì´ PDF: {result.get('total_pdf', 0)}ê°œ",
            f"- ì‹ ê·œ ì„ë² ë”©: {len(result.get('added', []))}ê°œ",
            f"- ê¸°ì¡´ ìŠ¤í‚µ: {len(result.get('skipped', []))}ê°œ",
        ]
        if result.get("failed"):
            summary_lines.append(f"- ì‹¤íŒ¨: {len(result['failed'])}ê°œ (ì•„ë˜ ì°¸ê³ )")

        st.chat_message("assistant").write("\n".join(summary_lines))

        # ì‹¤íŒ¨ê°€ ìˆìœ¼ë©´ ìƒì„¸ ì¶œë ¥
        if result.get("failed"):
            with st.expander("ì‹¤íŒ¨ ìƒì„¸ ë³´ê¸°", expanded=False):
                for fn, err in result["failed"][:20]:
                    st.code(f"{fn}\n{err}")

        # ì„¸ì…˜ ë©”ì‹œì§€ì—ë„ ë‚¨ê¸°ê¸°(ìƒˆë¡œê³ ì¹¨/ë¦¬ë Œë” ëŒ€ë¹„)
        st.session_state["messages"].append({"role": "assistant", "content": "\n".join(summary_lines)})

    # ====== ì°¸ê³ ìš©: ì„ë² ë”©ëœ PDF ëª©ë¡ ======
    with st.expander("ğŸ“š ì„ë² ë”©ëœ PDF ëª©ë¡(ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ê¸°ì¤€)", expanded=False):
        items = list_ingested_pdfs()
        if not items:
            st.write("ì•„ì§ ì„ë² ë”©ëœ PDFê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for it in items[:100]:
                st.write(f"- {it.get('original_name')} | {it.get('ingested_at')} | {it.get('sha256','')[:12]}")

    # ====== ì±„íŒ… ì…ë ¥/ì‘ë‹µ ======
    if prompt_message := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
        st.session_state["messages"].append({"role": "human", "content": prompt_message})
        st.chat_message("human").write(prompt_message)

        with st.chat_message("ai"):
            with st.spinner("Thinking..."):
                config = {"configurable": {"session_id": "any"}}
                try:
                    response = conversational_chain.invoke({"input": prompt_message}, config)
                except Exception as e:
                    st.error("ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                    st.code(str(e))
                    st.info(
                        "Ollama/ì„ë² ë”© ëª¨ë¸ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n"
                        "1) `ollama list`\n"
                        "2) `ollama pull qwen3-embedding` ë˜ëŠ” `ollama pull nomic-embed-text`\n"
                        "3) `streamlit cache clear` í›„ ì¬ì‹¤í–‰"
                    )
                    return

                answer = response.get("answer", "")
                st.write(answer)
                st.session_state["messages"].append({"role": "assistant", "content": answer})

                with st.expander("ì°¸ê³  ë¬¸ì„œ í™•ì¸"):
                    for doc in response.get("context", []) or []:
                        src = (doc.metadata or {}).get("source", "Unknown")
                        st.markdown(src, help=getattr(doc, "page_content", ""))